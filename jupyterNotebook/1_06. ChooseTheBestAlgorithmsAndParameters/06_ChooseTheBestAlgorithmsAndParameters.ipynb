{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Choose the best algorithms and parameters.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| | 観点 | 考慮点 | 解決策 |\n",
    "|---- | :---- | :---- | :---- |\n",
    "| 1 | アルゴリズムの選定 | 他にもっと高い正解率を出せるアルゴリズムがあるのではないか | 各アルゴリズムの正解率を比較する。|\n",
    "| 2 | アルゴリズムの評価 | データに関して、さまざまなパターンで行っても安定して良い結果をえられるか | クロスバリデーション。|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Compare the accuracy rate of each algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier の正解率 :  0.9\n",
      "BaggingClassifier の正解率 :  0.9333333333333333\n",
      "BernoulliNB の正解率 :  0.26666666666666666\n",
      "CalibratedClassifierCV の正解率 :  0.8\n",
      "ComplementNB の正解率 :  0.6666666666666666\n",
      "DecisionTreeClassifier の正解率 :  0.8333333333333334\n",
      "DummyClassifier の正解率 :  0.26666666666666666\n",
      "ExtraTreeClassifier の正解率 :  0.8333333333333334\n",
      "ExtraTreesClassifier の正解率 :  0.9\n",
      "GaussianNB の正解率 :  0.8666666666666667\n",
      "GaussianProcessClassifier の正解率 :  0.9333333333333333\n",
      "GradientBoostingClassifier の正解率 :  0.9\n",
      "HistGradientBoostingClassifier の正解率 :  0.9\n",
      "KNeighborsClassifier の正解率 :  0.9\n",
      "LabelPropagation の正解率 :  0.8666666666666667\n",
      "LabelSpreading の正解率 :  0.8666666666666667\n",
      "LinearDiscriminantAnalysis の正解率 :  0.9333333333333333\n",
      "LinearSVC の正解率 :  0.9\n",
      "LogisticRegression の正解率 :  0.8666666666666667\n",
      "LogisticRegressionCV の正解率 :  0.8333333333333334\n",
      "MLPClassifier の正解率 :  0.9\n",
      "MultinomialNB の正解率 :  0.8666666666666667\n",
      "NearestCentroid の正解率 :  0.8666666666666667\n",
      "NuSVC の正解率 :  0.9\n",
      "PassiveAggressiveClassifier の正解率 :  0.9\n",
      "Perceptron の正解率 :  0.6666666666666666\n",
      "QuadraticDiscriminantAnalysis の正解率 :  0.9333333333333333\n",
      "RadiusNeighborsClassifier の正解率 :  0.9666666666666667\n",
      "RandomForestClassifier の正解率 :  0.9\n",
      "RidgeClassifier の正解率 :  0.7333333333333333\n",
      "RidgeClassifierCV の正解率 :  0.7333333333333333\n",
      "SGDClassifier の正解率 :  0.8666666666666667\n",
      "SVC の正解率 :  0.9333333333333333\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6db14caa42d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m#! Create an object for each algorithm.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m#! fit= Machine learning.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'estimators'"
     ]
    }
   ],
   "source": [
    "#! From 03. Ayame code.\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "from sklearn.utils.testing import all_estimators # *UPDATE* #\n",
    "\n",
    "#!\n",
    "#! Read iris data.\n",
    "#!\n",
    "iris_data = pd.read_csv(\"iris.csv\", encoding=\"utf-8\")\n",
    "\n",
    "#!\n",
    "#! Separate iris data into labels and input data.\n",
    "#!\n",
    "# Separate by CSV header name\n",
    "y = iris_data.loc[:, \"Name\"]\n",
    "x = iris_data.loc[:, [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]]\n",
    "\n",
    "#!\n",
    "#! Divide into learning and testing.\n",
    "#!\n",
    "# Separate 80% for learning and 20% for testing.(Shuffle=Sort the original data randomly.)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, train_size = 0.8, shuffle = True)\n",
    "\n",
    "#!\n",
    "#! Learn.\n",
    "#!\n",
    "# *UPDATE* #\n",
    "# *** Get all Classifier algorithms. *** #\n",
    "warnings.filterwarnings('ignore')\n",
    "allAlgorithms = all_estimators(type_filter = 'classifier')\n",
    "\n",
    "for(name, algorithm) in allAlgorithms:\n",
    "    #print(name)\n",
    "    \n",
    "    if name in {\"CheckingClassifier\", \"ClassifierChain\", \"MultiOutputClassifier\", \"OneVsOneClassifier\", \"OneVsOneClassifier\", \\\n",
    "               \"OneVsRestClassifier\", \"OutputCodeClassifier\"}:\n",
    "        continue\n",
    "    \n",
    "    #! Create an object for each algorithm.\n",
    "    clf = algorithm()\n",
    "    \n",
    "    #! fit= Machine learning.\n",
    "    #print(x_train)\n",
    "    #print(y_train)\n",
    "    clf.fit(x_train, y_train)\n",
    "    #! Evaluation.(accuracy_score()=Calculation of accuracy rate.)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    #print(y_predict)\n",
    "    print(name, \"の正解率 : \", accuracy_score(y_test, y_predict))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ・Cross validation\n",
    "   - Divide the data into three groups, A, B and C.\n",
    "   - A and B are learning data, C is evaluation data, and the accuracy rate is shown.\n",
    "   - B and C are learning data, A is evaluation data, and the accuracy rate is shown.\n",
    "   - C and A are learning data, B is evaluation data, and the correct answer rate is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier の正解率 : \n",
      "[0.93333333 0.93333333 0.86666667 0.86666667 1.        ]\n",
      "BaggingClassifier の正解率 : \n",
      "[1.         1.         0.83333333 0.96666667 0.9       ]\n",
      "BernoulliNB の正解率 : \n",
      "[0.23333333 0.3        0.23333333 0.3        0.26666667]\n",
      "CalibratedClassifierCV の正解率 : \n",
      "[0.93333333 0.86666667 0.9        0.96666667 0.96666667]\n",
      "could not convert string to float: 'Iris-setosa'\n",
      "__init__() missing 1 required positional argument: 'base_estimator'\n",
      "ComplementNB の正解率 : \n",
      "[0.66666667 0.5        0.76666667 0.73333333 0.66666667]\n",
      "DecisionTreeClassifier の正解率 : \n",
      "[0.9        0.93333333 0.93333333 1.         0.9       ]\n",
      "DummyClassifier の正解率 : \n",
      "[0.33333333 0.3        0.23333333 0.3        0.43333333]\n",
      "ExtraTreeClassifier の正解率 : \n",
      "[0.96666667 0.9        0.96666667 0.86666667 0.93333333]\n",
      "ExtraTreesClassifier の正解率 : \n",
      "[0.96666667 0.93333333 0.9        0.96666667 0.96666667]\n",
      "GaussianNB の正解率 : \n",
      "[1.         0.96666667 0.96666667 0.93333333 0.9       ]\n",
      "GaussianProcessClassifier の正解率 : \n",
      "[0.93333333 0.93333333 1.         0.96666667 0.96666667]\n",
      "GradientBoostingClassifier の正解率 : \n",
      "[0.93333333 1.         0.93333333 0.96666667 0.9       ]\n",
      "HistGradientBoostingClassifier の正解率 : \n",
      "[0.96666667 0.9        0.96666667 1.         0.9       ]\n",
      "KNeighborsClassifier の正解率 : \n",
      "[1.         0.96666667 0.93333333 1.         0.96666667]\n",
      "LabelPropagation の正解率 : \n",
      "[0.96666667 1.         0.9        0.96666667 0.93333333]\n",
      "LabelSpreading の正解率 : \n",
      "[0.93333333 0.96666667 1.         0.93333333 0.96666667]\n",
      "LinearDiscriminantAnalysis の正解率 : \n",
      "[1.         1.         1.         0.93333333 1.        ]\n",
      "LinearSVC の正解率 : \n",
      "[0.9        0.9        1.         1.         0.96666667]\n",
      "LogisticRegression の正解率 : \n",
      "[0.96666667 1.         0.9        0.86666667 0.96666667]\n",
      "LogisticRegressionCV の正解率 : \n",
      "[0.93333333 0.9        0.96666667 1.         0.96666667]\n",
      "MLPClassifier の正解率 : \n",
      "[0.96666667 1.         0.96666667 1.         0.96666667]\n",
      "__init__() missing 1 required positional argument: 'estimator'\n",
      "MultinomialNB の正解率 : \n",
      "[0.73333333 0.8        0.96666667 0.96666667 0.96666667]\n",
      "NearestCentroid の正解率 : \n",
      "[0.96666667 0.93333333 0.83333333 0.93333333 0.93333333]\n",
      "NuSVC の正解率 : \n",
      "[0.96666667 1.         0.86666667 1.         0.9       ]\n",
      "__init__() missing 1 required positional argument: 'estimator'\n",
      "__init__() missing 1 required positional argument: 'estimator'\n",
      "__init__() missing 1 required positional argument: 'estimator'\n",
      "PassiveAggressiveClassifier の正解率 : \n",
      "[0.83333333 0.73333333 0.7        0.76666667 0.9       ]\n",
      "Perceptron の正解率 : \n",
      "[0.8        0.93333333 0.83333333 0.33333333 0.76666667]\n",
      "QuadraticDiscriminantAnalysis の正解率 : \n",
      "[1.         0.96666667 0.96666667 1.         0.93333333]\n",
      "RadiusNeighborsClassifier の正解率 : \n",
      "[0.93333333 0.93333333 1.         0.93333333 0.96666667]\n",
      "RandomForestClassifier の正解率 : \n",
      "[0.93333333 0.9        1.         0.9        1.        ]\n",
      "RidgeClassifier の正解率 : \n",
      "[0.76666667 0.76666667 0.86666667 0.76666667 0.9       ]\n",
      "RidgeClassifierCV の正解率 : \n",
      "[0.76666667 0.8        0.86666667 0.8        0.96666667]\n",
      "SGDClassifier の正解率 : \n",
      "[0.73333333 0.93333333 0.96666667 0.66666667 0.83333333]\n",
      "SVC の正解率 : \n",
      "[1.         1.         0.96666667 0.96666667 0.96666667]\n",
      "__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils.testing import all_estimators # *UPDATE* #\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#!\n",
    "#! Read iris data.\n",
    "#!\n",
    "iris_data = pd.read_csv(\"iris.csv\", encoding=\"utf-8\")\n",
    "\n",
    "#!\n",
    "#! Separate iris data into labels and input data.\n",
    "#!\n",
    "# Separate by CSV header name\n",
    "y = iris_data.loc[:, \"Name\"]\n",
    "x = iris_data.loc[:, [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]]\n",
    "\n",
    "#!\n",
    "#! Learn.\n",
    "#!\n",
    "# *UPDATE* #\n",
    "# *** Get all Classifier algorithms. *** #\n",
    "warnings.filterwarnings('ignore')\n",
    "allAlgorithms = all_estimators(type_filter = 'classifier')\n",
    "\n",
    "#! Object for K-split cross validation.\n",
    "kfold_cv = KFold(n_splits = 5, shuffle=True)\n",
    "\n",
    "for(name, algorithm) in allAlgorithms:\n",
    "    #print(name)\n",
    "    \n",
    "    # Insert TRY because some errors occur.\n",
    "    try:\n",
    "        #! Create an object for each algorithm.\n",
    "        clf = algorithm()\n",
    "        \n",
    "        #! Target class with score method.\n",
    "        if hasattr(clf, \"score\"):\n",
    "            #!\n",
    "            #! Cross validation.\n",
    "            #!\n",
    "            # clf: Classifier, x: Input data, y: Label, cv: Cross validation object.\n",
    "            score = cross_val_score(clf, x, y, cv = kfold_cv)\n",
    "            #print(y_predict)\n",
    "            print(name, \"の正解率 : \")    \n",
    "            print(score)    \n",
    "    except Exception as error:\n",
    "        print(str(error))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ・Find the best parameters.\n",
    "   - Grid search: \n",
    "      - High parameter tuning method.\n",
    "      - A method in which the correct answer rates are compared for all patterns of specified parameters,<br>\n",
    "        and a combination of parameters having the highest correct answer rate is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<Optimal parameters>> SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "--------------------------------------------\n",
      "<<grid_scores>>\n",
      " dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_kernel', 'param_gamma', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])\n",
      "<<Correct answer rate at evaluation>> 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#! Read iris data.\n",
    "iris_data = pd.read_csv(\"iris.csv\", encoding=\"utf-8\")\n",
    "\n",
    "#! Separate iris data into labels and input data.\n",
    "# Separate by CSV header name\n",
    "y = iris_data.loc[:, \"Name\"]\n",
    "x = iris_data.loc[:, [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]]\n",
    "\n",
    "#! Divide into learning and testing.\n",
    "# Separate 80% for learning and 20% for testing.(Shuffle=Sort the original data randomly.)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, train_size = 0.8, shuffle = True)\n",
    "\n",
    "#!\n",
    "#! Specify the parameters used in grid search.\n",
    "#!\n",
    "parameters = [\n",
    "    {\"C\": [1, 10, 100, 1000], \"kernel\":[\"linear\"]},\n",
    "    {\"C\": [1, 10, 100, 1000], \"kernel\":[\"rbf\"], \"gamma\": [0.001, 0.0001]},\n",
    "    {\"C\": [1, 10, 100, 1000], \"kernel\":[\"sigmoid\"], \"gamma\": [0.001, 0.0001]},\n",
    "             ]\n",
    "#!\n",
    "#! Perform a grid search.\n",
    "#!\n",
    "# Object for K-split cross validation.\n",
    "kfold_cv = KFold(n_splits = 5, shuffle=True)\n",
    "# Object for grid search.\n",
    "clf = GridSearchCV(SVC(), parameters, cv = kfold_cv)\n",
    "\n",
    "# Perform grid search by fit().\n",
    "clf.fit(x_train, y_train)\n",
    "print(\"<<Optimal parameters>>\", clf.best_estimator_)\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"<<grid_scores>>\\n\", clf.cv_results_.keys())\n",
    "\n",
    "#!\n",
    "#! Evaluate with optimal parameters.\n",
    "#!\n",
    "y_predict = clf.predict(x_test)\n",
    "print(\"<<Correct answer rate at evaluation>>\", accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
